{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bfbb94-14d2-4b88-a5cc-49e7032b2152",
   "metadata": {},
   "source": [
    "https://zenodo.org/records/7395397"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a6b7b2-5126-4aa9-88b0-c63a6a7aa798",
   "metadata": {},
   "source": [
    "https://www.biorxiv.org/content/10.1101/2023.04.26.538471v1.full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb320c6-fe9e-4f63-8047-2c5c56792234",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7ed825-db2e-4c92-9a46-27b21a526c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:24.656455Z",
     "iopub.status.busy": "2023-12-23T18:45:24.656301Z",
     "iopub.status.idle": "2023-12-23T18:45:27.918667Z",
     "shell.execute_reply": "2023-12-23T18:45:27.918207Z",
     "shell.execute_reply.started": "2023-12-23T18:45:24.656436Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c7a476-42b2-44fc-a5f1-73c811d974f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:27.919694Z",
     "iopub.status.busy": "2023-12-23T18:45:27.919464Z",
     "iopub.status.idle": "2023-12-23T18:45:27.922288Z",
     "shell.execute_reply": "2023-12-23T18:45:27.921916Z",
     "shell.execute_reply.started": "2023-12-23T18:45:27.919680Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change working dir\n",
    "os.chdir(\"/cellar/users/aklie/data/datasets/deBoer_random-promoters_GPRA/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab6972-4548-4881-aa26-cd5eab644324",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0446815-0c5a-41e0-8e9b-13998dc3bf48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49beb84-c527-4518-97bf-6891277ed4e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:27.922975Z",
     "iopub.status.busy": "2023-12-23T18:45:27.922813Z",
     "iopub.status.idle": "2023-12-23T18:45:36.485696Z",
     "shell.execute_reply": "2023-12-23T18:45:36.485294Z",
     "shell.execute_reply.started": "2023-12-23T18:45:27.922962Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6739258\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TGCATTTTTTTCACATCTCTTTGCCACGGGGTGAAGGATAGGATGG...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGCATTTTTTTCACATCTATGTTGCGTTAGAACGATATTGGAACAC...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TGCATTTTTTTCACATCTGTGAAGAATATCAGCTTTCAATCGTATT...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TGCATTTTTTTCACATCAATCCGAGATATCTGTTGATAAACTTACC...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGCATTTTTTTCACATCAAGTTATCTGGTGTACGTTTTCTCGTATA...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq   bin\n",
       "0  TGCATTTTTTTCACATCTCTTTGCCACGGGGTGAAGGATAGGATGG...  11.0\n",
       "1  TGCATTTTTTTCACATCTATGTTGCGTTAGAACGATATTGGAACAC...   6.0\n",
       "2  TGCATTTTTTTCACATCTGTGAAGAATATCAGCTTTCAATCGTATT...   8.0\n",
       "3  TGCATTTTTTTCACATCAATCCGAGATATCTGTTGATAAACTTACC...   9.0\n",
       "4  TGCATTTTTTTCACATCAAGTTATCTGGTGTACGTTTTCTCGTATA...  12.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read tabular\n",
    "train_valid = pd.read_table(\"dataset_preparation/2023_12_22/dream/train_sequences.txt\", header=None, sep=\"\\t\")\n",
    "train_valid.columns = [\"seq\", \"bin\"]\n",
    "print(len(train_valid))\n",
    "train_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb933232-097b-4364-82c4-cc5e1d3333f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e277901-6ff7-4141-9208-45e587c63ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:36.486903Z",
     "iopub.status.busy": "2023-12-23T18:45:36.486740Z",
     "iopub.status.idle": "2023-12-23T18:45:36.501835Z",
     "shell.execute_reply": "2023-12-23T18:45:36.501510Z",
     "shell.execute_reply.started": "2023-12-23T18:45:36.486889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mmh3\n",
    "\n",
    "\n",
    "def hash_fun(seq, seed):\n",
    "    return mmh3.hash(seq, seed, signed=False) % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06421b0-1daf-4fdd-adcb-f95b9093f7c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:36.502496Z",
     "iopub.status.busy": "2023-12-23T18:45:36.502316Z",
     "iopub.status.idle": "2023-12-23T18:45:41.885153Z",
     "shell.execute_reply": "2023-12-23T18:45:41.884742Z",
     "shell.execute_reply.started": "2023-12-23T18:45:36.502483Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    674870\n",
       "3    674634\n",
       "0    674598\n",
       "6    674300\n",
       "8    674223\n",
       "1    674008\n",
       "2    673957\n",
       "5    673238\n",
       "4    672990\n",
       "9    672440\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create fold split\n",
    "fold = list(map(lambda x: hash_fun(x, 1234), train_valid.seq))\n",
    "train_valid['fold'] = fold\n",
    "train_valid = train_valid.sort_values('fold')\n",
    "train_valid[\"fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff56a0-3e56-4d05-8d87-acab639ca2d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preprocess sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad625da-0343-4ee0-9578-108049c56743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:41.885928Z",
     "iopub.status.busy": "2023-12-23T18:45:41.885762Z",
     "iopub.status.idle": "2023-12-23T18:45:41.891768Z",
     "shell.execute_reply": "2023-12-23T18:45:41.891447Z",
     "shell.execute_reply.started": "2023-12-23T18:45:41.885914Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEFT_ADAPTER = \"TGCATTTTTTTCACATC\" \n",
    "RIGHT_ADAPTER = \"GGTTACGGCTGTT\"\n",
    "\n",
    "PLASMID = \"aactctcaaggatcttaccgctgttgagatccagttcgatgtaacccactcgtgcacccaactgatcttcagcatcttttactttcaccagcgtttctgggtgagcaaaaacaggaaggcaaaatgccgcaaaaaagggaataagggcgacacggaaatgttgaatactcatactcttcctttttcaatattattgaagcatttatcagggttattgtctcatgagcggatacatatttgaatgtatttagaaaaataaacaaataggggttccgcgcacatttccccgaaaagtgccacctgacgtcatctatattaccctgttatccctagcggatctgccggtagaggtgtggtcaataagagcgacctcatactatacctgagaaagcaacctgacctacaggaaagagttactcaagaataagaattttcgttttaaaacctaagagtcactttaaaatttgtatacacttattttttttataacttatttaataataaaaatcataaatcataagaaattcgcttatttagaagtGGCGCGCCGGTCCGttacttgtacagctcgtccatgccgccggtggagtggcggccctcggcgcgttcgtactgttccacgatggtgtagtcctcgttgtgggaggtgatgtccaacttgatgttgacgttgtaggcgccgggcagctgcacgggcttcttggccttgtaggtggtcttgacctcagcgtcgtagtggccgccgtccttcagcttcagcctctgcttgatctcgcccttcagggcgccgtcctcggggtacatccgctcggaggaggcctcccagcccatggtcttcttctgcattacggggccgtcggaggggaagttggtgccgcgcagcttcaccttgtagatgaactcgccgtcctgcagggaggagtcctgggtcacggtcaccacgccgccgtcctcgaagttcatcacgcgctcccacttgaagccctcggggaaggacagcttcaagtagtcggggatgtcggcggggtgcttcacgtaggccttggagccgtacatgaactgaggggacaggatgtcccaggcgaagggcagggggccacccttggtcaccttcagcttggcggtctgggtgccctcgtaggggcggccctcgccctcgccctcgatctcgaactcgtggccgttcacggagccctccatgtgcaccttgaagcgcatgaactccttgatgatggccatgttatcctcctcgcccttgctcacCATGGTACTAGTGTTTAGTTAATTATAGTTCGTTGACCGTATATTCTAAAAACAAGTACTCCTTAAAAAAAAACCTTGAAGGGAATAAACAAGTAGAATAGATAGAGAGAAAAATAGAAAATGCAAGAGAATTTATATATTAGAAAGAGAGAAAGAAAAATGGAAAAAAAAAAATAGGAAAAGCCAGAAATAGCACTAGAAGGAGCGACACCAGAAAAGAAGGTGATGGAACCAATTTAGCTATATATAGTTAACTACCGGCTCGATCATCTCTGCCTCCAGCATAGTCGAAGAAGAATTTTTTTTTTCTTGAGGCTTCTGTCAGCAACTCGTATTTTTTCTTTCTTTTTTGGTGAGCCTAAAAAGTTCCCACGTTCTCTTGTACGACGCCGTCACAAACAACCTTATGGGTAATTTGTCGCGGTCTGGGTGTATAAATGTGTGGGTGCAACATGAATGTACGGAGGTAGTTTGCTGATTGGCGGTCTATAGATACCTTGGTTATGGCGCCCTCACAGCCGGCAGGGGAAGCGCCTACGCTTGACATCTACTATATGTAAGTATACGGCCCCATATATAggccctttcgtctcgcgcgtttcggtgatgacggtgaaaacctctgacacatgcagctcccggagacggtcacagcttgtctgtaagcggatgccgggagcagacaagcccgtcagggcgcgtcagcgggtgttggcgggtgtcggggctggcttaactatgcggcatcagagcagattgtactgagagtgcaccatatggacatattgtcgttagaacgcggctacaattaatacataaccttatgtatcatacacatacgatttaggtgacactatagaacgcggccgccagctgaagctttaactatgcggcatcagagcagattgtactgagagtgcaccataccaccttttcaattcatcattttttttttattcttttttttgatttcggtttccttgaaatttttttgattcggtaatctccgaacagaaggaagaacgaaggaaggagcacagacttagattggtatatatacgcatatgtagtgttgaagaaacatgaaattgcccagtattcttaacccaactgcacagaacaaaaacctgcaggaaacgaagataaatcatgtcgaaagctacatataaggaacgtgctgctactcatcctagtcctgttgctgccaagctatttaatatcatgcacgaaaagcaaacaaacttgtgtgcttcattggatgttcgtaccaccaaggaattactggagttagttgaagcattaggtcccaaaatttgtttactaaaaacacatgtggatatcttgactgatttttccatggagggcacagttaagccgctaaaggcattatccgccaagtacaattttttactcttcgaagacagaaaatttgctgacattggtaatacagtcaaattgcagtactctgcgggtgtatacagaatagcagaatgggcagacattacgaatgcacacggtgtggtgggcccaggtattgttagcggtttgaagcaggcggcagaagaagtaacaaaggaacctagaggccttttgatgttagcagaattgtcatgcaagggctccctatctactggagaatatactaagggtactgttgacattgcgaagagcgacaaagattttgttatcggctttattgctcaaagagacatgggtggaagagatgaaggttacgattggttgattatgacacccggtgtgggtttagatgacaagggagacgcattgggtcaacagtatagaaccgtggatgatgtggtctctacaggatctgacattattattgttggaagaggactatttgcaaagggaagggatgctaaggtagagggtgaacgttacagaaaagcaggctgggaagcatatttgagaagatgcggccagcaaaactaaaaaactgtattataagtaaatgcatgtatactaaactcacaaattagagcttcaatttaattatatcagttattaccctatgcggtgtgaaataccgcacagatgcgtaaggagaaaataccgcatcaggaaattgtaagcgttaatattttgttaaaattcgcgttaaatttttgttaaatcagctcattttttaaccaataggccgaaatcggcaaaatcccttataaatcaaaagaatagaccgagatagggttgagtgttgttccagtttggaacaagagtccactattaaagaacgtggactccaacgtcaaagggcgaaaaaccgtctatcagggcgatggcccactacgtgaaccatcaccctaatcaagtGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATTTTTTTCACATCNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNGGTTACGGCTGTTTCTTAATTAAAAAAAGATAGAAAACATTAGGAGTGTAACACAAGACTTTCGGATCCTGAGCAGGCAAGATAAACGAAGGCAAAGatgtctaaaggtgaagaattattcactggtgttgtcccaattttggttgaattagatggtgatgttaatggtcacaaattttctgtctccggtgaaggtgaaggtgatgctacttacggtaaattgaccttaaaattgatttgtactactggtaaattgccagttccatggccaaccttagtcactactttaggttatggtttgcaatgttttgctagatacccagatcatatgaaacaacatgactttttcaagtctgccatgccagaaggttatgttcaagaaagaactatttttttcaaagatgacggtaactacaagaccagagctgaagtcaagtttgaaggtgataccttagttaatagaatcgaattaaaaggtattgattttaaagaagatggtaacattttaggtcacaaattggaatacaactataactctcacaatgtttacatcactgctgacaaacaaaagaatggtatcaaagctaacttcaaaattagacacaacattgaagatggtggtgttcaattagctgaccattatcaacaaaatactccaattggtgatggtccagtcttgttaccagacaaccattacttatcctatcaatctgccttatccaaagatccaaacgaaaagagagaccacatggtcttgttagaatttgttactgctgctggtattacccatggtatggatgaattgtacaaataaggcgcgccacttctaaataagcgaatttcttatgatttatgatttttattattaaataagttataaaaaaaataagtgtatacaaattttaaagtgactcttaggttttaaaacgaaaattcttattcttgagtaactctttcctgtaggtcaggttgctttctcaggtatagtatgaggtcgctcttattgaccacacctctaccggcagatccgctagggataacagggtaatataGATCTGTTTAGCTTGCCTCGTCCCCGCCGGGTCACCCGGCCAGCGACATGGAGGCCCAGAATACCCTCCTTGACAGTCTTGACGTGCGCAGCTCAGGGGCATGATGTGACTGTCGCCCGTACATTTAGCCCATACATCCCCATGTATAATCATTTGCATCCATACATTTTGATGGCCGCACGGCGCGAAGCAAAAATTACGGCTCCTCGCTGCAGACCTGCGAGCAGGGAAACGCTCCCCTCACAGACGCGTTGAATTGTCCCCACGCCGCGCCCCTGTAGAGAAATATAAAAGGTTAGGATTTGCCACTGAGGTTCTTCTTTCATATACTTCCTTTTAAAATCTTGCTAGGATACAGTTCTCACATCACATCCGAACATAAACAACCATGGGTACCACTCTTGACGACACGGCTTACCGGTACCGCACCAGTGTCCCGGGGGACGCCGAGGCCATCGAGGCACTGGATGGGTCCTTCACCACCGACACCGTCTTCCGCGTCACCGCCACCGGGGACGGCTTCACCCTGCGGGAGGTGCCGGTGGACCCGCCCCTGACCAAGGTGTTCCCCGACGACGAATCGGACGACGAATCGGACGACGGGGAGGACGGCGACCCGGACTCCCGGACGTTCGTCGCGTACGGGGACGACGGCGACCTGGCGGGCTTCGTGGTCGTCTCGTACTCCGGCTGGAACCGCCGGCTGACCGTCGAGGACATCGAGGTCGCCCCGGAGCACCGGGGGCACGGGGTCGGGCGCGCGTTGATGGGGCTCGCGACGGAGTTCGCCCGCGAGCGGGGCGCCGGGCACCTCTGGCTGGAGGTCACCAACGTCAACGCACCGGCGATCCACGCGTACCGGCGGATGGGGTTCACCCTCTGCGGCCTGGACACCGCCCTGTACGACGGCACCGCCTCGGACGGCGAGCAGGCGCTCTACATGAGCATGCCCTGCCCCTAATCAGTACTGACAATAAAAAGATTCTTGTTTTCAAGAACTTGTCATTTGTATAGTTTTTTTATATTGTAGTTGTTCTATTTTAATCAAATGTTAGCGTGATTTATATTTTTTTTCGCCTCGACATCATCTGCCCAGATGCGAAGTTAAGTGCGCAGAAAGTAATATCATGCGTCAATCGTATGTGAATGCTGGTCGCTATACTGCTGTCGATTCGATACTAACGCCGCCATCCAGTGTCGAAAACGAGCTCGaattcctgggtccttttcatcacgtgctataaaaataattataatttaaattttttaatataaatatataaattaaaaatagaaagtaaaaaaagaaattaaagaaaaaatagtttttgttttccgaagatgtaaaagactctagggggatcgccaacaaatactaccttttatcttgctcttcctgctctcaggtattaatgccgaattgtttcatcttgtctgtgtagaagaccacacacgaaaatcctgtgattttacattttacttatcgttaatcgaatgtatatctatttaatctgcttttcttgtctaataaatatatatgtaaagtacgctttttgttgaaattttttaaacctttgtttatttttttttcttcattccgtaactcttctaccttctttatttactttctaaaatccaaatacaaaacataaaaataaataaacacagagtaaattcccaaattattccatcattaaaagatacgaggcgcgtgtaagttacaggcaagcgatccgtccGATATCatcagatccactagtggcctatgcggccgcggatctgccggtctccctatagtgagtcgtattaatttcgataagccaggttaacctgcattaatgaatcggccaacgcgcggggagaggcggtttgcgtattgggcgctcttccgcttcctcgctcactgactcgctgcgctcggtcgttcggctgcggcgagcggtatcagctcactcaaaggcggtaatacggttatccacagaatcaggggataacgcaggaaagaacatgtgagcaaaaggccagcaaaaggccaggaaccgtaaaaaggccgcgttgctggcgtttttccataggctccgcccccctgacgagcatcacaaaaatcgacgctcaagtcagaggtggcgaaacccgacaggactataaagataccaggcgtttccccctggaagctccctcgtgcgctctcctgttccgaccctgccgcttaccggatacctgtccgcctttctcccttcgggaagcgtggcgctttctcaTAgctcacgctgtaggtatctcagttcggtgtaggtcgttcgctccaagctgggctgtgtgcacgaaccccccgttcagcccgaccgctgcgccttatccggtaactatcgtcttgagtccaacccggtaagacacgacttatcgccactggcagcagccactggtaacaggattagcagagcgaggtatgtaggcggtgctacagagttcttgaagtggtggcctaactacggctacactagaagAacagtatttggtatctgcgctctgctgaagccagttaccttcggaaaaagagttggtagctcttgatccggcaaacaaaccaccgctggtagcggtggtttttttgtttgcaagcagcagattacgcgcagaaaaaaaggatctcaagaagatcctttgatcttttctacggggtctgacgctcagtggaacgaaaactcacgttaagggattttggtcatgagattatcaaaaaggatcttcacctagatccttttaaattaaaaatgaagttttaaatcaatctaaagtatatatgagtaaacttggtctgacagttaccaatgcttaatcagtgaggcacctatctcagcgatctgtctatttcgttcatccatagttgcctgactccccgtcgtgtagataactacgatacgggagggcttaccatctggccccagtgctgcaatgataccgcgagacccacgTtcaccggctccagatttatcagcaataaaccagccagccggaagggccgagcgcagaagtggtcctgcaactttatccgcctccatccagtctattaattgttgccgggaagctagagtaagtagttcgccagttaatagtttgcgcaacgttgttgccattgctacaggcatcgtggtgtcacgctcgtcgtttggtatggcttcattcagctccggttcccaacgatcaaggcgagttacatgatcccccatgttgtgcaaaaaagcggttagctccttcggtcctccgatcgttgtcagaagtaagttggccgcagtgttatcactcatggttatggcagcactgcataattctcttactgtcatgccatccgtaagatgcttttctgtgactggtgagtactcaaccaagtcattctgagaatagtgtatgcggcgaccgagttgctcttgcccggcgtcaatacgggataataccgcgccacatagcagaactttaaaagtgctcatcattggaaaacgttcttcggggcgaa\"\n",
    "PLASMID = PLASMID.upper()\n",
    "INSERT_START = PLASMID.find('N'*80)\n",
    "\n",
    "\n",
    "def preprocess_data(data, length):\n",
    "    data = data.copy()\n",
    "    add_part = PLASMID[INSERT_START-length:INSERT_START]\n",
    "    data.seq = data.seq.apply(lambda x:  add_part + x[len(LEFT_ADAPTER):])\n",
    "    data.seq = data.seq.str.slice(-length, None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8a5f09-eb7f-4ad3-a23f-7de10f4ee26c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:41.892408Z",
     "iopub.status.busy": "2023-12-23T18:45:41.892232Z",
     "iopub.status.idle": "2023-12-23T18:45:47.188778Z",
     "shell.execute_reply": "2023-12-23T18:45:47.188374Z",
     "shell.execute_reply.started": "2023-12-23T18:45:41.892395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>bin</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4288439</th>\n",
       "      <td>AGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATT...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319238</th>\n",
       "      <td>AGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATT...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672928</th>\n",
       "      <td>AAGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCAT...</td>\n",
       "      <td>7.090078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672929</th>\n",
       "      <td>AGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATT...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485732</th>\n",
       "      <td>AGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATT...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       seq        bin  fold\n",
       "4288439  AGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATT...  11.000000     0\n",
       "5319238  AGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATT...  14.000000     0\n",
       "672928   AAGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCAT...   7.090078     0\n",
       "672929   AGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATT...  12.000000     0\n",
       "2485732  AGTGCTAGCAGGAATGATGCAAAAGGTTCCCGATTCGAACTGCATT...  14.000000     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid = preprocess_data(train_valid, 150)\n",
    "train_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4e8102-6d87-4ace-9a42-99b3f68c5260",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Add singleton column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ece180-905b-47a6-88a8-c6a5bd6731b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:47.189636Z",
     "iopub.status.busy": "2023-12-23T18:45:47.189476Z",
     "iopub.status.idle": "2023-12-23T18:45:47.193174Z",
     "shell.execute_reply": "2023-12-23T18:45:47.192849Z",
     "shell.execute_reply.started": "2023-12-23T18:45:47.189621Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_singleton(arr, method):\n",
    "    if method == \"integer\":\n",
    "        return np.array([x.is_integer() for x in arr])\n",
    "    elif method.startswith(\"threshold\"):\n",
    "        th = float(method.replace(\"threshold\", \"\"))\n",
    "        cnt = Counter(arr)\n",
    "        return np.array([cnt[x] >= th for x in arr])\n",
    "    else:\n",
    "        raise Exception(\"Wrong method\")\n",
    "\n",
    "        \n",
    "def add_singleton_column(df, method):\n",
    "    df = df.copy()\n",
    "    df[\"is_singleton\"] = infer_singleton(df.bin.values,method)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18450166-30d1-42a7-8b8b-c32089829fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:47.193902Z",
     "iopub.status.busy": "2023-12-23T18:45:47.193665Z",
     "iopub.status.idle": "2023-12-23T18:45:48.292676Z",
     "shell.execute_reply": "2023-12-23T18:45:48.292218Z",
     "shell.execute_reply.started": "2023-12-23T18:45:47.193889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_valid = add_singleton_column(train_valid, \"integer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884769d-f912-4633-b1cf-86777efd2df9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Add reverse complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d81d718-8b14-479c-8c34-a98da1142f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:48.616729Z",
     "iopub.status.busy": "2023-12-23T18:45:48.616515Z",
     "iopub.status.idle": "2023-12-23T18:45:48.621547Z",
     "shell.execute_reply": "2023-12-23T18:45:48.621198Z",
     "shell.execute_reply.started": "2023-12-23T18:45:48.616713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CODES = {\n",
    "    \"A\": 0,\n",
    "    \"T\": 3,\n",
    "    \"G\": 1,\n",
    "    \"C\": 2,\n",
    "    'N': 4\n",
    "}\n",
    "\n",
    "INV_CODES = {value: key for key, value in CODES.items()}\n",
    "\n",
    "COMPL = {\n",
    "    'A': 'T',\n",
    "    'T': 'A',\n",
    "    'G': 'C',\n",
    "    'C': 'G',\n",
    "    'N': 'N'\n",
    "}\n",
    "\n",
    "\n",
    "def revcomp(seq):\n",
    "    return \"\".join((n2compl(x) for x in reversed(seq)))\n",
    "\n",
    "def n2id(n):\n",
    "    return CODES[n.upper()]\n",
    "\n",
    "def id2n(i):\n",
    "    return INV_CODES[i]\n",
    "\n",
    "def n2compl(n):\n",
    "    return COMPL[n.upper()]\n",
    "\n",
    "def add_rev(df):\n",
    "    df = df.copy()\n",
    "    revdf = df.copy()\n",
    "    revdf['seq'] = df.seq.apply(revcomp)\n",
    "    df['rev'] = 0\n",
    "    revdf['rev'] = 1\n",
    "    df = pd.concat([df, revdf]).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7ebcc3-bdf8-4045-95ef-6b6840bf1794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:45:48.622194Z",
     "iopub.status.busy": "2023-12-23T18:45:48.622066Z",
     "iopub.status.idle": "2023-12-23T18:49:14.589965Z",
     "shell.execute_reply": "2023-12-23T18:49:14.589494Z",
     "shell.execute_reply.started": "2023-12-23T18:45:48.622181Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_valid = add_rev(train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a828ce6-8a7b-40b6-961f-6ba5ab09d15d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ff70fd-0835-41c2-afd9-72ef8de37c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:14.590855Z",
     "iopub.status.busy": "2023-12-23T18:49:14.590611Z",
     "iopub.status.idle": "2023-12-23T18:49:15.088767Z",
     "shell.execute_reply": "2023-12-23T18:49:15.088339Z",
     "shell.execute_reply.started": "2023-12-23T18:49:14.590839Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_valid[train_valid['fold'] != 9]\n",
    "valid = train_valid[train_valid['fold'] == 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2ea4f-17dd-4cac-9d10-2816fa799524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T18:03:47.221744Z",
     "iopub.status.busy": "2023-12-22T18:03:47.221601Z",
     "iopub.status.idle": "2023-12-22T18:07:08.336553Z",
     "shell.execute_reply": "2023-12-22T18:07:08.336073Z",
     "shell.execute_reply.started": "2023-12-22T18:03:47.221732Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca5d901-29b4-4b45-90a9-5b54af57cf43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:15.089583Z",
     "iopub.status.busy": "2023-12-23T18:49:15.089412Z",
     "iopub.status.idle": "2023-12-23T18:49:22.301482Z",
     "shell.execute_reply": "2023-12-23T18:49:22.300916Z",
     "shell.execute_reply.started": "2023-12-23T18:49:15.089569Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy\n",
    "\n",
    "\n",
    "class Seq2Tensor(nn.Module):\n",
    "    '''\n",
    "    Encode sequences using one-hot encoding after preprocessing.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, seq: str) -> torch.Tensor:\n",
    "        seq_i = [n2id(x) for x in seq]\n",
    "        code = torch.from_numpy(np.array(seq_i))\n",
    "        code = F.one_hot(code, num_classes=5) # 5th class is N\n",
    "\n",
    "        code = code[:, :5].float()\n",
    "        code[code[:, 4] == 1] = 0.25 # encode Ns with .25\n",
    "        code =  code[:, :4]\n",
    "        return code.transpose(0, 1)\n",
    "\n",
    "\n",
    "POINTS = np.array([-np.inf, *range(1, 18, 1), np.inf])\n",
    "class SeqDatasetProb(Dataset):\n",
    "    \n",
    "    \"\"\" Sequence dataset. \"\"\"\n",
    "    \n",
    "    def __init__(self, ds, seqsize, use_single_channel, use_reverse_channel, use_multisubstate_channel, shift=0.5, scale=0.5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ds : pd.DataFrame\n",
    "            Training dataset.\n",
    "        seqsize : int\n",
    "            Constant sequence length.\n",
    "        use_single_channel : bool\n",
    "            If True, additional binary channel with singleton information is used.\n",
    "        use_reverse_channel : bool\n",
    "            If True, additional reverse augmentation is used.\n",
    "        use_multisubstate_channel : bool\n",
    "            If True, additional substrate channel is used.\n",
    "        shift : float, optional\n",
    "            Assumed sd of real expression normal distribution.\n",
    "        scale : float, optional\n",
    "            Assumed scale of real expression normal distribution.\n",
    "        \"\"\"\n",
    "        self.ds = ds\n",
    "        self.seqsize = seqsize\n",
    "        self.totensor = Seq2Tensor() \n",
    "        self.shift = shift \n",
    "        self.scale = scale\n",
    "        self.use_single_channel = use_single_channel\n",
    "        self.use_reverse_channel = use_reverse_channel\n",
    "        self.use_multisubstate_channel = use_multisubstate_channel\n",
    "        \n",
    "    def transform(self, x):\n",
    "        assert isinstance(x, str)\n",
    "        assert len(x) == self.seqsize\n",
    "        return self.totensor(x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Output\n",
    "        ----------\n",
    "        X: torch.Tensor    \n",
    "            Create one-hot encoding tensor with reverse and singleton channels if required.\n",
    "        probs: np.ndarray\n",
    "            Given a measured expression, we assume that the real expression is normally distributed\n",
    "            with mean=`bin` and sd=`shift`. \n",
    "            Resulting `probs` vector contains probabilities that correspond to each class (bin).     \n",
    "        bin: float \n",
    "            Training expression value\n",
    "        \"\"\"\n",
    "        seq = self.transform(self.ds.seq.values[i])\n",
    "        to_concat = [seq]\n",
    "        \n",
    "        # add reverse augmentation channel\n",
    "        if self.use_reverse_channel:\n",
    "            rev = torch.full( (1, self.seqsize), self.ds.rev.values[i], dtype=torch.float32)\n",
    "            to_concat.append(rev)\n",
    "            \n",
    "        # add singleton channel\n",
    "        if self.use_single_channel:\n",
    "            single = torch.full( (1, self.seqsize) , self.ds.is_singleton.values[i], dtype=torch.float32)\n",
    "            to_concat.append(single)\n",
    "            \n",
    "        # add multiclass channel\n",
    "        if self.use_multisubstate_channel:\n",
    "            substrate = torch.full( (1, self.seqsize) , self.ds.substrate.values[i], dtype=torch.float32)\n",
    "            to_concat.append(substrate)\n",
    "        \n",
    "        # create final tensor\n",
    "        if len(to_concat) > 1:\n",
    "            X = torch.concat(to_concat, dim=0)\n",
    "        else:\n",
    "            X = seq\n",
    "            \n",
    "        bin = self.ds.bin.values[i]\n",
    "        \n",
    "        # generate probabilities corresponding to each class\n",
    "        norm = scipy.stats.norm(loc=bin + self.shift, scale=self.scale)\n",
    "        \n",
    "        cumprobs = norm.cdf(POINTS)\n",
    "        probs = cumprobs[1:] - cumprobs[:-1]\n",
    "        return X, probs, bin\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds.seq)\n",
    "    \n",
    "    \n",
    "class DataloaderWrapper:\n",
    "    def __init__(self, dataloader, batch_per_epoch):\n",
    "        self.batch_per_epoch = batch_per_epoch\n",
    "        self.dataloader = dataloader\n",
    "        self.iterator = iter(dataloader)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_per_epoch\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            return next(self.iterator)\n",
    "        except StopIteration:\n",
    "            self.iterator = iter(self.dataloader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.batch_per_epoch):\n",
    "            try:\n",
    "                yield next(self.iterator)\n",
    "            except StopIteration:\n",
    "                self.iterator = iter(self.dataloader)\n",
    "                \n",
    "                \n",
    "def create_dl(train, valid, \n",
    "              seqsize,\n",
    "              use_single_channel, use_reverse_channel, use_multisubstate_channel,\n",
    "              train_batch_size, train_workers,\n",
    "              valid_batch_size, valid_workers,\n",
    "              batch_per_epoch,\n",
    "              SeqDatasetProb,\n",
    "              shuffle_train=True, shuffle_val=False):\n",
    "    \n",
    "    train_ds = SeqDatasetProb(train, \n",
    "                             seqsize=seqsize, \n",
    "                             use_single_channel=use_single_channel,\n",
    "                             use_reverse_channel=use_reverse_channel,\n",
    "                             use_multisubstate_channel=use_multisubstate_channel,\n",
    "                             )\n",
    "\n",
    "    train_dl = DataLoader(train_ds, \n",
    "                          batch_size=train_batch_size,\n",
    "                          num_workers=train_workers,\n",
    "                          shuffle=shuffle_train) \n",
    "\n",
    "    train_dl = DataloaderWrapper(train_dl, batch_per_epoch)\n",
    "    \n",
    "    if valid is None:\n",
    "        return train_dl, None\n",
    "    \n",
    "    valid_ds = SeqDatasetProb(valid, \n",
    "                            seqsize=seqsize, \n",
    "                            use_single_channel=use_single_channel,\n",
    "                            use_reverse_channel=use_reverse_channel,\n",
    "                            use_multisubstate_channel=use_multisubstate_channel\n",
    "                            )\n",
    "\n",
    "    valid_dl = DataLoader(valid_ds, \n",
    "                        batch_size=valid_batch_size,\n",
    "                        num_workers=valid_workers,\n",
    "                        shuffle=shuffle_val) \n",
    "    \n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d98c2003-8f83-432f-9ac1-59664f5243df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:22.302445Z",
     "iopub.status.busy": "2023-12-23T18:49:22.302207Z",
     "iopub.status.idle": "2023-12-23T18:49:22.327616Z",
     "shell.execute_reply": "2023-12-23T18:49:22.327127Z",
     "shell.execute_reply.started": "2023-12-23T18:49:22.302431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl, valid_dl = create_dl(\n",
    "    train, \n",
    "    valid,\n",
    "    150, \n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    128,\n",
    "    0,\n",
    "    128,\n",
    "    0,\n",
    "    1000,\n",
    "    SeqDatasetProb,\n",
    "    True, \n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "303f533c-483b-4d85-9ade-8f8e4cae9b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:22.328387Z",
     "iopub.status.busy": "2023-12-23T18:49:22.328246Z",
     "iopub.status.idle": "2023-12-23T18:49:25.159244Z",
     "shell.execute_reply": "2023-12-23T18:49:25.158746Z",
     "shell.execute_reply.started": "2023-12-23T18:49:22.328373Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 6, 150]), torch.Size([128, 18]), torch.Size([128]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "batch[0].shape, batch[1].shape, batch[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e4d1b-8116-4f1a-8f41-ab15372c2b8c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f8c9519-bf79-424a-9992-6349ca89a18f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:25.160038Z",
     "iopub.status.busy": "2023-12-23T18:49:25.159884Z",
     "iopub.status.idle": "2023-12-23T18:49:25.778469Z",
     "shell.execute_reply": "2023-12-23T18:49:25.777930Z",
     "shell.execute_reply.started": "2023-12-23T18:49:25.160024Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from legnet import SeqNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb87d766-3331-4706-be47-e910f6324240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:25.779860Z",
     "iopub.status.busy": "2023-12-23T18:49:25.779414Z",
     "iopub.status.idle": "2023-12-23T18:49:27.683921Z",
     "shell.execute_reply": "2023-12-23T18:49:27.683352Z",
     "shell.execute_reply.started": "2023-12-23T18:49:25.779832Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = SeqNN(\n",
    "    seqsize=150,\n",
    "    use_single_channel=True,\n",
    "    block_sizes=[256, 128, 128, 64, 64, 64, 64],\n",
    "    ks=7,\n",
    "    resize_factor=4, \n",
    "    se_reduction=4, \n",
    "    bn_momentum=0.1,\n",
    "    final_ch=18\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55328edb-44cf-46b6-8d45-9c5c1505bed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:27.684760Z",
     "iopub.status.busy": "2023-12-23T18:49:27.684610Z",
     "iopub.status.idle": "2023-12-23T18:49:27.689758Z",
     "shell.execute_reply": "2023-12-23T18:49:27.689059Z",
     "shell.execute_reply.started": "2023-12-23T18:49:27.684746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        n = m.kernel_size[0] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2 / n))\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_(0, 0.001)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a1c6771-e255-4ce2-9e8e-44236f82daf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:27.690529Z",
     "iopub.status.busy": "2023-12-23T18:49:27.690386Z",
     "iopub.status.idle": "2023-12-23T18:49:27.708837Z",
     "shell.execute_reply": "2023-12-23T18:49:27.708357Z",
     "shell.execute_reply.started": "2023-12-23T18:49:27.690516Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06bb1781-c63a-44d7-825f-f0b9e6f6c792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:27.709562Z",
     "iopub.status.busy": "2023-12-23T18:49:27.709421Z",
     "iopub.status.idle": "2023-12-23T18:49:27.719293Z",
     "shell.execute_reply": "2023-12-23T18:49:27.718865Z",
     "shell.execute_reply.started": "2023-12-23T18:49:27.709549Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.KLDivLoss(reduction= \"batchmean\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e256d2cb-34b0-499e-b8e9-61423b827795",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:27.719946Z",
     "iopub.status.busy": "2023-12-23T18:49:27.719812Z",
     "iopub.status.idle": "2023-12-23T18:49:30.647524Z",
     "shell.execute_reply": "2023-12-23T18:49:30.646916Z",
     "shell.execute_reply.started": "2023-12-23T18:49:27.719934Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y_probs, y = next(iter(train_dl))\n",
    "X = X.to(device)\n",
    "y_probs = y_probs.float().to(device)\n",
    "logprobs, y_pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b664d32-e2af-4dea-8d71-d368dae3a1fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:30.648511Z",
     "iopub.status.busy": "2023-12-23T18:49:30.648299Z",
     "iopub.status.idle": "2023-12-23T18:49:30.661338Z",
     "shell.execute_reply": "2023-12-23T18:49:30.660896Z",
     "shell.execute_reply.started": "2023-12-23T18:49:30.648495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0119, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(logprobs, y_probs)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec816a7e-d941-43d2-b162-3b6e3443530b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095f9e5f-dddc-4902-a34c-4df96d1bf0bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:30.662253Z",
     "iopub.status.busy": "2023-12-23T18:49:30.662109Z",
     "iopub.status.idle": "2023-12-23T18:49:42.276021Z",
     "shell.execute_reply": "2023-12-23T18:49:42.275400Z",
     "shell.execute_reply.started": "2023-12-23T18:49:30.662240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics import MeanSquaredError, PearsonCorrCoef, SpearmanCorrCoef\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "        \n",
    "class MyModel(LightningModule):\n",
    "    def __init__(self, model, criterion, optimizer, scheduler, model_dir, use_validation):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.model_dir = Path(model_dir)\n",
    "        self.model_dir.mkdir(exist_ok=True, parents=True)\n",
    "        self.use_validation = use_validation\n",
    "\n",
    "        #\n",
    "        self.validation_step_outputs = []\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.train_pearson = PearsonCorrCoef()\n",
    "        self.train_spearman = SpearmanCorrCoef()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.val_pearson = PearsonCorrCoef()\n",
    "        self.val_spearman = SpearmanCorrCoef()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the model\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Unpack data\n",
    "        X, y_probs, y = batch\n",
    "        logprobs, y_pred = self(X)  # Forward pass\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(logprobs, y_probs)\n",
    "\n",
    "        # Calculate metrics\n",
    "        self.train_mse.update(y_pred.detach(), y)\n",
    "        self.train_pearson.update(y_pred.detach(), y)\n",
    "        self.train_spearman.update(y_pred.detach(), y)\n",
    "\n",
    "        # Logging\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_mse', self.train_mse, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_pearson', self.train_pearson, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_spearman', self.train_spearman, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_probs, y = batch\n",
    "        logprobs, y_pred = self(X)  # Forward pass\n",
    "        \n",
    "        loss = self.criterion(logprobs, y_probs)\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        self.val_mse.update(y_pred, y)\n",
    "        self.val_pearson.update(y_pred, y)\n",
    "        self.val_spearman.update(y_pred, y)\n",
    "        \n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Log validation metrics\n",
    "        self.log('val_mse', self.val_mse.compute(), prog_bar=True)\n",
    "        self.log('val_pearson', self.val_pearson.compute(), prog_bar=True)\n",
    "        self.log('val_spearman', self.val_spearman.compute(), prog_bar=True)\n",
    "\n",
    "        # Reset metrics\n",
    "        self.val_mse.reset()\n",
    "        self.val_pearson.reset()\n",
    "        self.val_spearman.reset()\n",
    "        \n",
    "        # Reset loss\n",
    "        epoch_average = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"validation_epoch_average\", epoch_average)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Set up optimizers and schedulers\n",
    "        optimizer = self.optimizer\n",
    "        scheduler = {\n",
    "            'scheduler': self.scheduler,\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Save models and scores at the end of each epoch\n",
    "        model_path = self.model_dir / f\"model_{self.current_epoch}.pth\"\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "        optimizer_path = self.model_dir / f\"optimizer_{self.current_epoch}.pth\"\n",
    "        torch.save(self.optimizer.state_dict(), optimizer_path)\n",
    "\n",
    "        if self.scheduler is not None:\n",
    "            scheduler_path = self.model_dir / f\"scheduler_{self.current_epoch}.pth\"\n",
    "            torch.save(self.scheduler.state_dict(), scheduler_path)\n",
    "\n",
    "        if self.use_validation:\n",
    "            score_path = self.model_dir / f\"scores_{self.current_epoch}.json\"\n",
    "            with open(score_path, \"w\") as outp:\n",
    "                json.dump(self.trainer.callback_metrics, outp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9ec1395-3f1a-43f0-8ad7-c37a400245a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:42.276975Z",
     "iopub.status.busy": "2023-12-23T18:49:42.276821Z",
     "iopub.status.idle": "2023-12-23T18:49:42.281908Z",
     "shell.execute_reply": "2023-12-23T18:49:42.281447Z",
     "shell.execute_reply.started": "2023-12-23T18:49:42.276958Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer_name, model_params, lr, weight_decay):\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_params, lr = lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        optimizer = torch.optim.AdamW(model_params, lr = lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(model_params, lr = lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise Exception(\"Wrong optimizer\")\n",
    "    return optimizer\n",
    "\n",
    "optimizer = get_optimizer(\"adamw\", model.parameters(), 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f2b7b77-9d95-46b3-a9c8-1087decd8a06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:42.282752Z",
     "iopub.status.busy": "2023-12-23T18:49:42.282503Z",
     "iopub.status.idle": "2023-12-23T18:49:42.294110Z",
     "shell.execute_reply": "2023-12-23T18:49:42.293651Z",
     "shell.execute_reply.started": "2023-12-23T18:49:42.282738Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chosen_lr = 10e-2\n",
    "max_lr, div_factor = chosen_lr, 25.0\n",
    "min_lr = max_lr / div_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e61e3cc8-613b-4364-85ea-db2c16bd2eae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:42.294818Z",
     "iopub.status.busy": "2023-12-23T18:49:42.294680Z",
     "iopub.status.idle": "2023-12-23T18:49:42.305858Z",
     "shell.execute_reply": "2023-12-23T18:49:42.305402Z",
     "shell.execute_reply.started": "2023-12-23T18:49:42.294805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=max_lr,\n",
    "    div_factor=div_factor,\n",
    "    steps_per_epoch=1000, \n",
    "    epochs=450, \n",
    "    pct_start=0.3,\n",
    "    three_phase=\"store_true\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3d7b0c2-31a7-4f39-bcbe-75ca319a3ab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:42.306547Z",
     "iopub.status.busy": "2023-12-23T18:49:42.306411Z",
     "iopub.status.idle": "2023-12-23T18:49:42.318033Z",
     "shell.execute_reply": "2023-12-23T18:49:42.317603Z",
     "shell.execute_reply.started": "2023-12-23T18:49:42.306534Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parameter_count(model):\n",
    "    pars = 0  \n",
    "    for _, p  in model.named_parameters():    \n",
    "        pars += torch.prod(torch.tensor(p.shape))\n",
    "    return pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13281f51-5821-4e42-9e3a-1e6f13103958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:42.320670Z",
     "iopub.status.busy": "2023-12-23T18:49:42.320338Z",
     "iopub.status.idle": "2023-12-23T18:49:42.333332Z",
     "shell.execute_reply": "2023-12-23T18:49:42.332839Z",
     "shell.execute_reply.started": "2023-12-23T18:49:42.320655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 1852846\n"
     ]
    }
   ],
   "source": [
    "print('Model parameters:', int(parameter_count(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8cefda-2a21-4486-80bf-a7067d626bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T18:49:42.334052Z",
     "iopub.status.busy": "2023-12-23T18:49:42.333909Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib ...\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:277: RuntimeWarning: A `OneCycleLR` scheduler is using 'interval': 'epoch'. Are you sure you didn't mean 'interval': 'step'?\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | model          | SeqNN            | 1.9 M \n",
      "1 | criterion      | KLDivLoss        | 0     \n",
      "2 | train_mse      | MeanSquaredError | 0     \n",
      "3 | train_pearson  | PearsonCorrCoef  | 0     \n",
      "4 | train_spearman | SpearmanCorrCoef | 0     \n",
      "5 | val_mse        | MeanSquaredError | 0     \n",
      "6 | val_pearson    | PearsonCorrCoef  | 0     \n",
      "7 | val_spearman   | SpearmanCorrCoef | 0     \n",
      "----------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.411     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424aca0e2aef4e99ba25c02dbe1f1bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d7122e48cb4fc1a495ed19d42b1137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127577d12c8a40aa9e61997bd3fb0ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937015fdda4e453baf6f3ac95e070b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyModel(model, criterion, optimizer, scheduler, model_dir=\"bin/data_exploration/\", use_validation=True)\n",
    "\n",
    "# Set up the trainer\n",
    "trainer = Trainer(max_epochs=450)  # Set the number of epochs and other parameters as needed\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_dl, valid_dl)  # Provide your DataLoaders here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff133969-ea1a-4859-81ff-ea773737cfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4469a-31dd-4c3d-93d6-7c6596629b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38945e69-8f2d-4d39-a3fa-0758efdcd91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd4fa9-ec73-455d-897a-2cf47b658229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ba3dd-1779-4b3c-9d47-67a4193949af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13986872-19f7-4a5a-8018-27abab00fe2f",
   "metadata": {},
   "source": [
    "## SeqData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "967a0088-ed3f-4fac-88a3-58526e5feae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T17:37:50.804818Z",
     "iopub.status.busy": "2023-12-22T17:37:50.804614Z",
     "iopub.status.idle": "2023-12-22T17:37:50.808111Z",
     "shell.execute_reply": "2023-12-22T17:37:50.807783Z",
     "shell.execute_reply.started": "2023-12-22T17:37:50.804804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(left_adapter), len(right_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d94a7bbb-b028-4cd8-9b34-7bbe3590389e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T17:43:34.578183Z",
     "iopub.status.busy": "2023-12-22T17:43:34.578032Z",
     "iopub.status.idle": "2023-12-22T17:43:34.581191Z",
     "shell.execute_reply": "2023-12-22T17:43:34.580830Z",
     "shell.execute_reply.started": "2023-12-22T17:43:34.578169Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdata = xr.Dataset({\"seq\": xr.DataArray(train_df[\"seq\"].values, dims=\"_sequence\"), \n",
    "            \"expression_level\": xr.DataArray(train_df[\"expression_level\"].values, dims=\"_sequence\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "227520b9-4587-4c70-a0b6-c2582e89e88e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T17:43:53.685680Z",
     "iopub.status.busy": "2023-12-22T17:43:53.685396Z",
     "iopub.status.idle": "2023-12-22T17:44:04.130115Z",
     "shell.execute_reply": "2023-12-22T17:44:04.129689Z",
     "shell.execute_reply.started": "2023-12-22T17:43:53.685663Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import seqpro as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7f1f15a-3a6d-4227-a37b-8316797c500d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T17:45:55.168522Z",
     "iopub.status.busy": "2023-12-22T17:45:55.168163Z",
     "iopub.status.idle": "2023-12-22T17:46:03.221912Z",
     "shell.execute_reply": "2023-12-22T17:46:03.221554Z",
     "shell.execute_reply.started": "2023-12-22T17:45:55.168501Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.500000e+01, 4.422000e+03, 1.455900e+04, 3.206600e+04,\n",
       "        1.117866e+06, 5.564716e+06, 1.977000e+03, 1.731000e+03,\n",
       "        1.427000e+03, 4.690000e+02]),\n",
       " array([ 78. ,  84.4,  90.8,  97.2, 103.6, 110. , 116.4, 122.8, 129.2,\n",
       "        135.6, 142. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sp.length(sdata[\"seq\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fad28a-fd57-4bb6-81ab-26bcf61657c2",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c05953d-d361-4691-b1c5-0e76ddd342a8",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
